{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166544e5-2fe5-4dd7-9235-fad4b9d9e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is the process of extracting data from websites by using automated software or tools, known as web scrapers. \n",
    "The extracted data is usually in a structured format and can be used for various purposes such as data analysis, research, and business intelligence.\n",
    "Web scraping is used to gather data from different sources such as social media platforms, e-commerce websites, news websites, and job portals.\n",
    "Some of the areas where web scraping is widely used are:\n",
    "\n",
    "E-commerce: Web scraping is used to monitor product prices, track competitors' prices, and gather product reviews from various e-commerce websites.\n",
    "\n",
    "Social media: Web scraping is used to gather data from social media platforms such as Facebook, Twitter, and LinkedIn for sentiment analysis,\n",
    "market research, and lead generation.\n",
    "\n",
    "Research and Analytics: Web scraping is used in various research and analytics projects to gather data from different \n",
    "sources such as academic websites, government portals, and scientific journals.\n",
    "\n",
    "------------------------------------------------------------------------------------------>\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "There are several methods used for web scraping, and some of the popular methods are:\n",
    "\n",
    "Using web scraping libraries: Web scraping libraries such as BeautifulSoup, Scrapy, and Requests can be used to extract data from websites. \n",
    "These libraries provide tools and functions to extract data from HTML and XML documents.\n",
    "\n",
    "Using APIs: Some websites provide APIs (Application Programming Interfaces) to extract data from their platforms. \n",
    "APIs are designed to provide a structured way of accessing data from websites.\n",
    "\n",
    "Using browser extensions: Browser extensions such as Web Scraper and Data Miner can be used to extract data from websites. \n",
    "These extensions allow users to create custom scrapers to extract data from web pages.\n",
    "\n",
    "Using web scraping services: There are several web scraping services available in the market that provide web scraping tools\n",
    "and services to extract data from websites\n",
    "\n",
    "---------------------------------------------------------------------------------------->\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping purposes. It is used to extract data from HTML and XML documents.\n",
    "Beautiful Soup provides a set of functions and tools to navigate and search HTML and XML documents. \n",
    "It can also parse poorly formatted HTML and XML documents.\n",
    "Beautiful Soup is used for web scraping because of its simplicity, flexibility, and compatibility with different web scraping projects. \n",
    "It can handle different types of HTML and XML documents and provides easy-to-use tools for extracting data from web pages.\n",
    "\n",
    "----------------------------------------------------------------------------------------->\n",
    "\n",
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a Python web framework used for developing web applications. \n",
    "It is a lightweight framework that provides tools and functions for building web applications quickly and easily.\n",
    "Flask is used in this web scraping project to create a web interface that allows users to input URLs and retrieve the extracted data.\n",
    "Flask provides a simple and flexible way of creating web applications.\n",
    "It also provides tools for handling different types of HTTP requests and responses. \n",
    "Flask can be easily integrated with other Python libraries such as Beautiful Soup to extract data from web pages\n",
    "\n",
    "----------------------------------------------------------------------------------------->\n",
    "\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "two service used in the project are elastic beanstalk and code pipeline\n",
    "AWS Elastic Beanstalk is a fully managed service that simplifies the deployment of web applications to AWS.\n",
    "It allows users to upload their web applications and provides tools to automatically handle the deployment process.\n",
    "Beanstalk provides a scalable and highly available platform to deploy and manage web applications.\n",
    "\n",
    "AWS CodePipeline is a fully managed continuous delivery service that automates the build, test, and deployment of web applications. \n",
    "It allows users to define their build and deployment process and provides tools to automate the entire process.\n",
    "CodePipeline integrates with other AWS services such as AWS CodeBuild and AWS CodeDeploy to provide a complete continuous delivery pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
